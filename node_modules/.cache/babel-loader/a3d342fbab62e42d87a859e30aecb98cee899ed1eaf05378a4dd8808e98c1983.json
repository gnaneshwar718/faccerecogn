{"ast":null,"code":"import*as faceapi from'face-api.js';// Function to load face-api.js models\nexport const loadFaceRecognitionModels=async()=>{await faceapi.nets.tinyFaceDetector.loadFromUri('/models');await faceapi.nets.faceLandmark68Net.loadFromUri('/models');await faceapi.nets.faceRecognitionNet.loadFromUri('/models');await faceapi.nets.ageGenderNet.loadFromUri('/models');// Add this line\n};// Function to detect faces in an image or video element, including age and gender\nexport const detectFaces=async input=>{const detections=await faceapi.detectAllFaces(input,new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceDescriptors().withAgeAndGender();// Add this line\nreturn detections;};// Function to match detected faces with known faces\nexport const matchFaces=(descriptors,faceDescriptor)=>{const faceMatcher=new faceapi.FaceMatcher(descriptors);const bestMatch=faceMatcher.findBestMatch(faceDescriptor);return bestMatch;};","map":{"version":3,"names":["faceapi","loadFaceRecognitionModels","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","ageGenderNet","detectFaces","input","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","withFaceDescriptors","withAgeAndGender","matchFaces","descriptors","faceDescriptor","faceMatcher","FaceMatcher","bestMatch","findBestMatch"],"sources":["C:/Users/NNN/Desktop/New folder/face recogniser/webcam-facial-recognition/src/utils/faceRecognition.ts"],"sourcesContent":["import * as faceapi from 'face-api.js';\r\n\r\n// Function to load face-api.js models\r\nexport const loadFaceRecognitionModels = async () => {\r\n    await faceapi.nets.tinyFaceDetector.loadFromUri('/models');\r\n    await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\r\n    await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\r\n    await faceapi.nets.ageGenderNet.loadFromUri('/models'); // Add this line\r\n};\r\n\r\n// Function to detect faces in an image or video element, including age and gender\r\nexport const detectFaces = async (input: HTMLImageElement | HTMLVideoElement) => {\r\n    const detections = await faceapi.detectAllFaces(\r\n        input,\r\n        new faceapi.TinyFaceDetectorOptions()\r\n    )\r\n        .withFaceLandmarks()\r\n        .withFaceDescriptors()\r\n        .withAgeAndGender(); // Add this line\r\n\r\n    return detections;\r\n};\r\n\r\n// Function to match detected faces with known faces\r\nexport const matchFaces = (descriptors: faceapi.LabeledFaceDescriptors[], faceDescriptor: Float32Array) => {\r\n    const faceMatcher = new faceapi.FaceMatcher(descriptors);\r\n    const bestMatch = faceMatcher.findBestMatch(faceDescriptor);\r\n    return bestMatch;\r\n};\r\n\r\nexport interface FaceDetails {\r\n    detection: faceapi.FaceDetection;\r\n    landmarks: faceapi.FaceLandmarks68;\r\n    name?: string;\r\n    age?: number;\r\n    gender?: string;\r\n}\r\n"],"mappings":"AAAA,MAAO,GAAK,CAAAA,OAAO,KAAM,aAAa,CAEtC;AACA,MAAO,MAAM,CAAAC,yBAAyB,CAAG,KAAAA,CAAA,GAAY,CACjD,KAAM,CAAAD,OAAO,CAACE,IAAI,CAACC,gBAAgB,CAACC,WAAW,CAAC,SAAS,CAAC,CAC1D,KAAM,CAAAJ,OAAO,CAACE,IAAI,CAACG,iBAAiB,CAACD,WAAW,CAAC,SAAS,CAAC,CAC3D,KAAM,CAAAJ,OAAO,CAACE,IAAI,CAACI,kBAAkB,CAACF,WAAW,CAAC,SAAS,CAAC,CAC5D,KAAM,CAAAJ,OAAO,CAACE,IAAI,CAACK,YAAY,CAACH,WAAW,CAAC,SAAS,CAAC,CAAE;AAC5D,CAAC,CAED;AACA,MAAO,MAAM,CAAAI,WAAW,CAAG,KAAO,CAAAC,KAA0C,EAAK,CAC7E,KAAM,CAAAC,UAAU,CAAG,KAAM,CAAAV,OAAO,CAACW,cAAc,CAC3CF,KAAK,CACL,GAAI,CAAAT,OAAO,CAACY,uBAAuB,CAAC,CACxC,CAAC,CACIC,iBAAiB,CAAC,CAAC,CACnBC,mBAAmB,CAAC,CAAC,CACrBC,gBAAgB,CAAC,CAAC,CAAE;AAEzB,MAAO,CAAAL,UAAU,CACrB,CAAC,CAED;AACA,MAAO,MAAM,CAAAM,UAAU,CAAGA,CAACC,WAA6C,CAAEC,cAA4B,GAAK,CACvG,KAAM,CAAAC,WAAW,CAAG,GAAI,CAAAnB,OAAO,CAACoB,WAAW,CAACH,WAAW,CAAC,CACxD,KAAM,CAAAI,SAAS,CAAGF,WAAW,CAACG,aAAa,CAACJ,cAAc,CAAC,CAC3D,MAAO,CAAAG,SAAS,CACpB,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}
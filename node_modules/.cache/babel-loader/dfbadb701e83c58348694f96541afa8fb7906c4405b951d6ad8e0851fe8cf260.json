{"ast":null,"code":"import * as faceapi from 'face-api.js';\n\n// Function to load face-api.js models\nexport const loadFaceRecognitionModels = async () => {\n  await faceapi.nets.tinyFaceDetector.loadFromUri('/models');\n  await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\n  await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\n  await faceapi.nets.ageGenderNet.loadFromUri('/models'); // Add this line\n};\n\n// Function to detect faces in an image or video element, including age and gender\nexport const detectFaces = async input => {\n  const detections = await faceapi.detectAllFaces(input, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceDescriptors().withAgeAndGender(); // Add this line\n\n  return detections;\n};\n\n// Function to match detected faces with known faces\nexport const matchFaces = (descriptors, faceDescriptor) => {\n  const faceMatcher = new faceapi.FaceMatcher(descriptors);\n  const bestMatch = faceMatcher.findBestMatch(faceDescriptor);\n  return bestMatch;\n};","map":{"version":3,"names":["faceapi","loadFaceRecognitionModels","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","ageGenderNet","detectFaces","input","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","withFaceDescriptors","withAgeAndGender","matchFaces","descriptors","faceDescriptor","faceMatcher","FaceMatcher","bestMatch","findBestMatch"],"sources":["C:/Users/NNN/Desktop/New folder/face recogniser/webcam-facial-recognition/src/utils/faceRecognition.ts"],"sourcesContent":["import * as faceapi from 'face-api.js';\r\n\r\n// Function to load face-api.js models\r\nexport const loadFaceRecognitionModels = async () => {\r\n    await faceapi.nets.tinyFaceDetector.loadFromUri('/models');\r\n    await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\r\n    await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\r\n    await faceapi.nets.ageGenderNet.loadFromUri('/models'); // Add this line\r\n};\r\n\r\n// Function to detect faces in an image or video element, including age and gender\r\nexport const detectFaces = async (input: HTMLImageElement | HTMLVideoElement) => {\r\n    const detections = await faceapi.detectAllFaces(\r\n        input,\r\n        new faceapi.TinyFaceDetectorOptions()\r\n    )\r\n        .withFaceLandmarks()\r\n        .withFaceDescriptors()\r\n        .withAgeAndGender(); // Add this line\r\n\r\n    return detections;\r\n};\r\n\r\n// Function to match detected faces with known faces\r\nexport const matchFaces = (descriptors: faceapi.LabeledFaceDescriptors[], faceDescriptor: Float32Array) => {\r\n    const faceMatcher = new faceapi.FaceMatcher(descriptors);\r\n    const bestMatch = faceMatcher.findBestMatch(faceDescriptor);\r\n    return bestMatch;\r\n};\r\n\r\nexport interface FaceDetails {\r\n    detection: faceapi.FaceDetection;\r\n    landmarks: faceapi.FaceLandmarks68;\r\n    name?: string;\r\n    age?: number;\r\n    gender?: string;\r\n}\r\n"],"mappings":"AAAA,OAAO,KAAKA,OAAO,MAAM,aAAa;;AAEtC;AACA,OAAO,MAAMC,yBAAyB,GAAG,MAAAA,CAAA,KAAY;EACjD,MAAMD,OAAO,CAACE,IAAI,CAACC,gBAAgB,CAACC,WAAW,CAAC,SAAS,CAAC;EAC1D,MAAMJ,OAAO,CAACE,IAAI,CAACG,iBAAiB,CAACD,WAAW,CAAC,SAAS,CAAC;EAC3D,MAAMJ,OAAO,CAACE,IAAI,CAACI,kBAAkB,CAACF,WAAW,CAAC,SAAS,CAAC;EAC5D,MAAMJ,OAAO,CAACE,IAAI,CAACK,YAAY,CAACH,WAAW,CAAC,SAAS,CAAC,CAAC,CAAC;AAC5D,CAAC;;AAED;AACA,OAAO,MAAMI,WAAW,GAAG,MAAOC,KAA0C,IAAK;EAC7E,MAAMC,UAAU,GAAG,MAAMV,OAAO,CAACW,cAAc,CAC3CF,KAAK,EACL,IAAIT,OAAO,CAACY,uBAAuB,CAAC,CACxC,CAAC,CACIC,iBAAiB,CAAC,CAAC,CACnBC,mBAAmB,CAAC,CAAC,CACrBC,gBAAgB,CAAC,CAAC,CAAC,CAAC;;EAEzB,OAAOL,UAAU;AACrB,CAAC;;AAED;AACA,OAAO,MAAMM,UAAU,GAAGA,CAACC,WAA6C,EAAEC,cAA4B,KAAK;EACvG,MAAMC,WAAW,GAAG,IAAInB,OAAO,CAACoB,WAAW,CAACH,WAAW,CAAC;EACxD,MAAMI,SAAS,GAAGF,WAAW,CAACG,aAAa,CAACJ,cAAc,CAAC;EAC3D,OAAOG,SAAS;AACpB,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}